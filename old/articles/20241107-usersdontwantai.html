<title>Users don't want AI, users want good software that works</title>
<date-posted>2024-07-11</date-posted>
<body>
	<p>When I was in university studying computer science, all anyone wanted to talk about was ML. I was not that interested, but I noticed it more and more from students and recruiters and job listings. ML was going to change and improve everything about the world, drastically. I don’t think I heard anyone really propose a plan for that, the technology was still progressing. But of course, it was going to be the next big thing, all the companies and universities had to hop on it!</p>
	<p>Except ML is hard, finding good training data is hard, and more than that all avoiding bias is hard. Google once released a photo recognition software to photos and tagged black people as monkeys. The only way they fixed it was by banning monkeys. That sounds like it really improved our lives.</p>
	<p>I once told a manager during an interview that I wasn’t interested in ML, and they replied, “wow, that’s refreshing.” All anyone wants to do is ML, but ML can’t really exist by itself. ML instead is more a means to help achieve a goal, but it can’t be the entire solution.</p>
	<p>It’s been 5 years since I graduated, I fail to see any way that ML has resulted in something that meaningfully improves my life. What aspect of the technology I use is improved by ML?</p>
	<p>My searches? No, not really, I now append “Reddit” to most of the things I search, to find discussions from real people, and not content farms or long texts before every recipe that are optimized for the algorithm. Google even attempted to take advantage of this by using Reddit to train an AI, and it created worse nonsense. </p>
	<p>Spotify won’t stop playing the same song I hate, no matter how many times I skip it.</p>
	<p>Facebook and Instagram now only show me posts by celebrities or famous pages I don’t care about. When I want to see a notification, clicking on it takes me to a random point in a page. I no longer see posts from those I care about, instead I’m constantly advertised to by both the platform and the users of the platform.</p>
	<p>I can still never decide on the best nearby restaurant, because the results change for every zoom level and pan, impossible to track. Also, it doesn’t matter to me that both restaurants are 5km away, when one is in a convenient transit location, and the other is on the other side of a highway.</p>
	<p>There’s no regard for correctness, or user input, into the things we want to see. Instead, the algorithm decides. There’s no way to filter for concise results, no way to ignore or dislike songs in Spotify, no way to see what comment my family made on a post when they tagged me, no way to tell Instagram I want to see posts from my friends instead of what it thinks I want to see, no way to tell Google Maps I only care about restaurants on the one street with good transit near me.</p>
	<p>And *now* we’re in the era of “AI”. How convenient we have a new two letter acronym, basically just ML in a fancy hat, that we can use to throw tons of money and resources into with very little actual gain. None of these companies even have good ways of making their AIs as profitable as all the resources they’re sinking into them, except for the brand recognition they lose by not keeping up.</p>
	<p>Sure an AI can be fun to chat to, a lot of people I know enjoy using generated AI images to make memes with friends. (Not that any of them would ever pay for that, or turn off their ad blocks enough to make it worth it).</p>
	<p>Especially not when AI is basically intellectual property theft, and no one would ever want to pay enough to correctly compensating the people who’s art is used in these generators. Instead, AI copies and reproduces their art with no credit and compensation. (Sarah Anderson wrote a good article on this).</p>
	<p>But AI at the end of the day is risky, it’s basically a randomness simulator that could always share inappropriate information, especially to the incorrect audience. We’re a long ways away from being able to actually trust the image or text returned from an AI. Should we ever? When the data used is always going to be biased, when the engineers will also always carry bias? </p>
	<p>What users <b>actually</b> want is for things to work when they use them. They want good, seamless, and easy to use software that improves their lives. Very little of the work we do is to achieve this goal… very little of the work I do is to achieve this goal.</p>
	<p>When I go to the doctor, I want to be listened to and not have my concerns dismissed. I don’t want an AI to predict what my condition is, or an AI nurse to perform my patient intake, because averages aren’t very important in individualized patient care. Instead, it’ll probably just give the doctor a reason to send me home with a temporary fix or useless prescription, as usual.</p>
	<p>When I call my internet provider wanting to fix an issue, I don’t want an AI to respond with things I’ve already tried, requiring me to type nonsense before I finally get connected with a real person. When I receive a call about a package for pickup, I don’t want the robot to use voice recognition software to guess which menu option I selected. When I try to find a recipe, I don’t want to read a pages and pages of a generated description to please content algorithms. When I look at an image, I want the people who’s work contributed to it to receive the proper credit and compensation.</p>
	<p>The user wants software to work, to get the service and support they deserve for their money and attention spent. If this means paying for people to do the work we’re trying to replace with an AI, it’s worth it. If this means that executives pockets are lined with less money and regular people can actually afford to live, it’s worth it.</p>
	<p>Investing in delivering quality to and respecting real people will always be actually worth it.</p>
</body>
